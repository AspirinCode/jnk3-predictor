{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_formats = ['svg']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../../../data/2_all_active_autoencoder_inactive/2DRDKit/for_ml/train_set/x_train.pickle\", \"rb\") as file:\n",
    "    x_train = pickle.load(file)\n",
    "\n",
    "with open(\"../../../../data/2_all_active_autoencoder_inactive/2DRDKit/for_ml/train_set/y_train.pickle\", \"rb\") as file:\n",
    "    y_train = pickle.load(file)\n",
    "\n",
    "with open(\"../../../../data/2_all_active_autoencoder_inactive/2DRDKit/for_ml/internal_test_set/internal_x_test.pickle\", \"rb\") as file:\n",
    "    internal_x_test = pickle.load(file)\n",
    "\n",
    "with open(\"../../../../data/2_all_active_autoencoder_inactive/2DRDKit/for_ml/internal_test_set/internal_y_test.pickle\", \"rb\") as file:\n",
    "    internal_y_test = pickle.load(file)\n",
    "\n",
    "with open(\"../../../../data/2_all_active_autoencoder_inactive/2DRDKit/for_ml/external_test_set/external_x_test.pickle\", \"rb\") as file:\n",
    "    external_x_test = pickle.load(file)\n",
    "\n",
    "with open(\"../../../../data/2_all_active_autoencoder_inactive/2DRDKit/for_ml/external_test_set/external_y_test.pickle\", \"rb\") as file:\n",
    "    external_y_test = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "      <th>65</th>\n",
       "      <th>66</th>\n",
       "      <th>67</th>\n",
       "      <th>68</th>\n",
       "      <th>69</th>\n",
       "      <th>70</th>\n",
       "      <th>71</th>\n",
       "      <th>72</th>\n",
       "      <th>73</th>\n",
       "      <th>74</th>\n",
       "      <th>75</th>\n",
       "      <th>76</th>\n",
       "      <th>77</th>\n",
       "      <th>78</th>\n",
       "      <th>79</th>\n",
       "      <th>80</th>\n",
       "      <th>81</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "      <th>84</th>\n",
       "      <th>85</th>\n",
       "      <th>86</th>\n",
       "      <th>87</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>102</th>\n",
       "      <th>103</th>\n",
       "      <th>104</th>\n",
       "      <th>105</th>\n",
       "      <th>106</th>\n",
       "      <th>107</th>\n",
       "      <th>108</th>\n",
       "      <th>109</th>\n",
       "      <th>110</th>\n",
       "      <th>111</th>\n",
       "      <th>112</th>\n",
       "      <th>113</th>\n",
       "      <th>114</th>\n",
       "      <th>115</th>\n",
       "      <th>116</th>\n",
       "      <th>117</th>\n",
       "      <th>118</th>\n",
       "      <th>119</th>\n",
       "      <th>120</th>\n",
       "      <th>121</th>\n",
       "      <th>122</th>\n",
       "      <th>123</th>\n",
       "      <th>124</th>\n",
       "      <th>125</th>\n",
       "      <th>126</th>\n",
       "      <th>127</th>\n",
       "      <th>128</th>\n",
       "      <th>129</th>\n",
       "      <th>130</th>\n",
       "      <th>131</th>\n",
       "      <th>132</th>\n",
       "      <th>133</th>\n",
       "      <th>134</th>\n",
       "      <th>135</th>\n",
       "      <th>136</th>\n",
       "      <th>137</th>\n",
       "      <th>138</th>\n",
       "      <th>139</th>\n",
       "      <th>140</th>\n",
       "      <th>141</th>\n",
       "      <th>142</th>\n",
       "      <th>143</th>\n",
       "      <th>144</th>\n",
       "      <th>145</th>\n",
       "      <th>146</th>\n",
       "      <th>147</th>\n",
       "      <th>148</th>\n",
       "      <th>149</th>\n",
       "      <th>150</th>\n",
       "      <th>151</th>\n",
       "      <th>152</th>\n",
       "      <th>153</th>\n",
       "      <th>154</th>\n",
       "      <th>155</th>\n",
       "      <th>156</th>\n",
       "      <th>157</th>\n",
       "      <th>158</th>\n",
       "      <th>159</th>\n",
       "      <th>160</th>\n",
       "      <th>161</th>\n",
       "      <th>162</th>\n",
       "      <th>163</th>\n",
       "      <th>164</th>\n",
       "      <th>165</th>\n",
       "      <th>166</th>\n",
       "      <th>167</th>\n",
       "      <th>168</th>\n",
       "      <th>169</th>\n",
       "      <th>170</th>\n",
       "      <th>171</th>\n",
       "      <th>172</th>\n",
       "      <th>173</th>\n",
       "      <th>174</th>\n",
       "      <th>175</th>\n",
       "      <th>176</th>\n",
       "      <th>177</th>\n",
       "      <th>178</th>\n",
       "      <th>179</th>\n",
       "      <th>180</th>\n",
       "      <th>181</th>\n",
       "      <th>182</th>\n",
       "      <th>183</th>\n",
       "      <th>184</th>\n",
       "      <th>185</th>\n",
       "      <th>186</th>\n",
       "      <th>187</th>\n",
       "      <th>188</th>\n",
       "      <th>189</th>\n",
       "      <th>190</th>\n",
       "      <th>191</th>\n",
       "      <th>192</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>12.138731</td>\n",
       "      <td>0.078403</td>\n",
       "      <td>12.138731</td>\n",
       "      <td>0.078403</td>\n",
       "      <td>0.622431</td>\n",
       "      <td>274.181</td>\n",
       "      <td>265.109</td>\n",
       "      <td>274.984935</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1.5625</td>\n",
       "      <td>2.3125</td>\n",
       "      <td>2.339042</td>\n",
       "      <td>681.724018</td>\n",
       "      <td>10.957819</td>\n",
       "      <td>8.459863</td>\n",
       "      <td>10.172935</td>\n",
       "      <td>7.860173</td>\n",
       "      <td>5.02607</td>\n",
       "      <td>6.648715</td>\n",
       "      <td>3.522526</td>\n",
       "      <td>5.594479</td>\n",
       "      <td>2.482263</td>\n",
       "      <td>4.815131</td>\n",
       "      <td>1.70548</td>\n",
       "      <td>3.799793</td>\n",
       "      <td>-1.570519</td>\n",
       "      <td>9923.302413</td>\n",
       "      <td>9.640986</td>\n",
       "      <td>3.779548</td>\n",
       "      <td>1.452937</td>\n",
       "      <td>98.738738</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98.579986</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.379009</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.562482</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.951108</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.687386</td>\n",
       "      <td>5.559267</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.295119</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>59.391841</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.333759</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.794537</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.291904</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.07361</td>\n",
       "      <td>4.260148</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.159786</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.04292</td>\n",
       "      <td>0.078403</td>\n",
       "      <td>12.138731</td>\n",
       "      <td>0.853105</td>\n",
       "      <td>1.116204</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.687305</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0477</td>\n",
       "      <td>66.485</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1          2         3         4        5        6  \\\n",
       "332  12.138731  0.078403  12.138731  0.078403  0.622431  274.181  265.109   \n",
       "\n",
       "              7     8    9  10  11  12  13     14      15      16        17  \\\n",
       "332  274.984935  78.0  0.0 NaN NaN NaN NaN  0.875  1.5625  2.3125  2.339042   \n",
       "\n",
       "             18         19        20         21        22       23        24  \\\n",
       "332  681.724018  10.957819  8.459863  10.172935  7.860173  5.02607  6.648715   \n",
       "\n",
       "           25        26        27        28       29        30        31  \\\n",
       "332  3.522526  5.594479  2.482263  4.815131  1.70548  3.799793 -1.570519   \n",
       "\n",
       "              32        33        34        35         36   37   38   39   40  \\\n",
       "332  9923.302413  9.640986  3.779548  1.452937  98.738738  0.0  0.0  0.0  0.0   \n",
       "\n",
       "      41         42   43   44   45   46   47   48   49   50   51         52  \\\n",
       "332  0.0  98.579986  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  24.379009   \n",
       "\n",
       "      53        54   55   56   57         58   59        60        61   62  \\\n",
       "332  0.0  3.562482  0.0  0.0  0.0  64.951108  0.0  5.687386  5.559267  0.0   \n",
       "\n",
       "      63   64         65   66   67   68         69   70         71   72    73  \\\n",
       "332  0.0  0.0  18.295119  0.0  0.0  0.0  59.391841  0.0  15.333759  0.0  22.0   \n",
       "\n",
       "      74        75   76         77   78        79        80   81         82  \\\n",
       "332  0.0  4.794537  0.0  20.291904  0.0  11.07361  4.260148  0.0  58.159786   \n",
       "\n",
       "      83   84       85        86         87        88        89   90  \\\n",
       "332  0.0  0.0  3.04292  0.078403  12.138731  0.853105  1.116204  0.0   \n",
       "\n",
       "            91   92   93   94   95    96   97   98   99  100  101  102  103  \\\n",
       "332  17.687305  0.0  0.0  0.0  0.0  16.0  0.0  2.0  0.0  0.0  0.0  2.0  1.0   \n",
       "\n",
       "     104  105  106  107  108  109  110  111  112     113     114  115  116  \\\n",
       "332  3.0  2.0  0.0  3.0  1.0  0.0  0.0  0.0  3.0  2.0477  66.485  0.0  0.0   \n",
       "\n",
       "     117  118  119  120  121  122  123  124  125  126  127  128  129  130  \\\n",
       "332  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0   \n",
       "\n",
       "     131  132  133  134  135  136  137  138  139  140  141  142  143  144  \\\n",
       "332  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "     145  146  147  148  149  150  151  152  153  154  155  156  157  158  \\\n",
       "332  0.0  0.0  0.0  0.0  2.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "     159  160  161  162  163  164  165  166  167  168  169  170  171  172  \\\n",
       "332  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "     173  174  175  176  177  178  179  180  181  182  183  184  185  186  \\\n",
       "332  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "     187  188  189  190  191  192  193  194  195  196  197  198  199  \n",
       "332  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_df = pd.DataFrame(data=x_train)\n",
    "x_train_df[x_train_df[13].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_df.at[332, 10] = 0.269756\n",
    "x_train_df.at[332, 11] = -0.462673\n",
    "x_train_df.at[332, 12] = 0.462673\n",
    "x_train_df.at[332, 13] = 0.269756\n",
    "x_train = x_train_df.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_params = [\n",
    "    {\n",
    "        \"C\": 0.001,\n",
    "        \"kernel\": \"rbf\",\n",
    "        \"gamma\": \"scale\",\n",
    "        \"shrinking\": True,\n",
    "    },\n",
    "    {\n",
    "        \"C\": 0.01,\n",
    "        \"kernel\": \"rbf\",\n",
    "        \"gamma\": \"scale\",\n",
    "        \"shrinking\": True,\n",
    "    },\n",
    "    {\n",
    "        \"C\": 0.1,\n",
    "        \"kernel\": \"rbf\",\n",
    "        \"gamma\": \"scale\",\n",
    "        \"shrinking\": True,\n",
    "    },\n",
    "    {\n",
    "        \"C\": 1,\n",
    "        \"kernel\": \"rbf\",\n",
    "        \"gamma\": \"scale\",\n",
    "        \"shrinking\": True,\n",
    "    },\n",
    "    {\n",
    "        \"C\": 10,\n",
    "        \"kernel\": \"rbf\",\n",
    "        \"gamma\": \"scale\",\n",
    "        \"shrinking\": True,\n",
    "    },\n",
    "    {\n",
    "        \"C\": 100,\n",
    "        \"kernel\": \"rbf\",\n",
    "        \"gamma\": \"scale\",\n",
    "        \"shrinking\": True,\n",
    "    },\n",
    "    {\n",
    "        \"C\": 0.001,\n",
    "        \"kernel\": \"rbf\",\n",
    "        \"gamma\": \"auto\",\n",
    "        \"shrinking\": True,\n",
    "    },\n",
    "    {\n",
    "        \"C\": 0.01,\n",
    "        \"kernel\": \"rbf\",\n",
    "        \"gamma\": \"auto\",\n",
    "        \"shrinking\": True,\n",
    "    },\n",
    "    {\n",
    "        \"C\": 0.1,\n",
    "        \"kernel\": \"rbf\",\n",
    "        \"gamma\": \"auto\",\n",
    "        \"shrinking\": True,\n",
    "    },\n",
    "    {\n",
    "        \"C\": 1,\n",
    "        \"kernel\": \"rbf\",\n",
    "        \"gamma\": \"auto\",\n",
    "        \"shrinking\": True,\n",
    "    },\n",
    "    {\n",
    "        \"C\": 10,\n",
    "        \"kernel\": \"rbf\",\n",
    "        \"gamma\": \"auto\",\n",
    "        \"shrinking\": True,\n",
    "    },\n",
    "    {\n",
    "        \"C\": 100,\n",
    "        \"kernel\": \"rbf\",\n",
    "        \"gamma\": \"auto\",\n",
    "        \"shrinking\": True,\n",
    "    },\n",
    "    {\n",
    "        \"C\": 0.001,\n",
    "        \"kernel\": \"rbf\",\n",
    "        \"gamma\": \"scale\",\n",
    "        \"shrinking\": False,\n",
    "    },\n",
    "    {\n",
    "        \"C\": 0.01,\n",
    "        \"kernel\": \"rbf\",\n",
    "        \"gamma\": \"scale\",\n",
    "        \"shrinking\": False,\n",
    "    },\n",
    "    {\n",
    "        \"C\": 0.1,\n",
    "        \"kernel\": \"rbf\",\n",
    "        \"gamma\": \"scale\",\n",
    "        \"shrinking\": False,\n",
    "    },\n",
    "    {\n",
    "        \"C\": 1,\n",
    "        \"kernel\": \"rbf\",\n",
    "        \"gamma\": \"scale\",\n",
    "        \"shrinking\": False,\n",
    "    },\n",
    "    {\n",
    "        \"C\": 10,\n",
    "        \"kernel\": \"rbf\",\n",
    "        \"gamma\": \"scale\",\n",
    "        \"shrinking\": False,\n",
    "    },\n",
    "    {\n",
    "        \"C\": 100,\n",
    "        \"kernel\": \"rbf\",\n",
    "        \"gamma\": \"scale\",\n",
    "        \"shrinking\": False,\n",
    "    },\n",
    "    {\n",
    "        \"C\": 0.001,\n",
    "        \"kernel\": \"rbf\",\n",
    "        \"gamma\": \"auto\",\n",
    "        \"shrinking\": False,\n",
    "    },\n",
    "    {\n",
    "        \"C\": 0.01,\n",
    "        \"kernel\": \"rbf\",\n",
    "        \"gamma\": \"auto\",\n",
    "        \"shrinking\": False,\n",
    "    },\n",
    "    {\n",
    "        \"C\": 0.1,\n",
    "        \"kernel\": \"rbf\",\n",
    "        \"gamma\": \"auto\",\n",
    "        \"shrinking\": False,\n",
    "    },\n",
    "    {\n",
    "        \"C\": 1,\n",
    "        \"kernel\": \"rbf\",\n",
    "        \"gamma\": \"auto\",\n",
    "        \"shrinking\": False,\n",
    "    },\n",
    "    {\n",
    "        \"C\": 10,\n",
    "        \"kernel\": \"rbf\",\n",
    "        \"gamma\": \"auto\",\n",
    "        \"shrinking\": False,\n",
    "    },\n",
    "    {\n",
    "        \"C\": 100,\n",
    "        \"kernel\": \"rbf\",\n",
    "        \"gamma\": \"auto\",\n",
    "        \"shrinking\": False,\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    }
   ],
   "source": [
    "print(len(svm_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "model fits\n",
      "model predicted\n",
      "int stats calculated\n",
      "ext stats calculated\n",
      "1\n",
      "model fits\n",
      "model predicted\n",
      "int stats calculated\n",
      "ext stats calculated\n",
      "2\n",
      "model fits\n",
      "model predicted\n",
      "int stats calculated\n",
      "ext stats calculated\n",
      "3\n",
      "model fits\n",
      "model predicted\n",
      "int stats calculated\n",
      "ext stats calculated\n",
      "4\n",
      "model fits\n",
      "model predicted\n",
      "int stats calculated\n",
      "ext stats calculated\n",
      "5\n",
      "model fits\n",
      "model predicted\n",
      "int stats calculated\n",
      "ext stats calculated\n",
      "6\n",
      "model fits\n",
      "model predicted\n",
      "int stats calculated\n",
      "ext stats calculated\n",
      "7\n",
      "model fits\n",
      "model predicted\n",
      "int stats calculated\n",
      "ext stats calculated\n",
      "8\n",
      "model fits\n",
      "model predicted\n",
      "int stats calculated\n",
      "ext stats calculated\n",
      "9\n",
      "model fits\n",
      "model predicted\n",
      "int stats calculated\n",
      "ext stats calculated\n",
      "10\n",
      "model fits\n",
      "model predicted\n",
      "int stats calculated\n",
      "ext stats calculated\n",
      "11\n",
      "model fits\n",
      "model predicted\n",
      "int stats calculated\n",
      "ext stats calculated\n",
      "12\n",
      "model fits\n",
      "model predicted\n",
      "int stats calculated\n",
      "ext stats calculated\n",
      "13\n",
      "model fits\n",
      "model predicted\n",
      "int stats calculated\n",
      "ext stats calculated\n",
      "14\n",
      "model fits\n",
      "model predicted\n",
      "int stats calculated\n",
      "ext stats calculated\n",
      "15\n",
      "model fits\n",
      "model predicted\n",
      "int stats calculated\n",
      "ext stats calculated\n",
      "16\n",
      "model fits\n",
      "model predicted\n",
      "int stats calculated\n",
      "ext stats calculated\n",
      "17\n",
      "model fits\n",
      "model predicted\n",
      "int stats calculated\n",
      "ext stats calculated\n",
      "18\n",
      "model fits\n",
      "model predicted\n",
      "int stats calculated\n",
      "ext stats calculated\n",
      "19\n",
      "model fits\n",
      "model predicted\n",
      "int stats calculated\n",
      "ext stats calculated\n",
      "20\n",
      "model fits\n",
      "model predicted\n",
      "int stats calculated\n",
      "ext stats calculated\n",
      "21\n",
      "model fits\n",
      "model predicted\n",
      "int stats calculated\n",
      "ext stats calculated\n",
      "22\n",
      "model fits\n",
      "model predicted\n",
      "int stats calculated\n",
      "ext stats calculated\n",
      "23\n",
      "model fits\n",
      "model predicted\n",
      "int stats calculated\n",
      "ext stats calculated\n"
     ]
    }
   ],
   "source": [
    "with open(\"./training_testing_results.csv\", \"w\") as log_file:\n",
    "    log_file.write(\"c,kernel,gamma,shrinking,int_precision,int_recall,int_fbeta,ext_precision,ext_recall,ext_fbeta\\n\")\n",
    "    for n, model_params in enumerate(svm_params):\n",
    "        print(n)\n",
    "        # log_file.write(f\"Model {n}\\n\")\n",
    "        # log_file.write(f\"Penalty: {model_params[\"penalty\"]}, C: {model_params[\"C\"]}\\n\")\n",
    "        log_file.write(f\"{model_params['C']},{model_params['kernel']},{model_params['gamma']},{model_params['shrinking']},\")\n",
    "        \n",
    "        # first we create a model with one of the optimized parameter sets\n",
    "        print(\"model fits\")\n",
    "        svm_model = SVC(C=model_params[\"C\"], kernel=model_params[\"kernel\"], \n",
    "                        gamma=model_params[\"gamma\"], shrinking=model_params[\"shrinking\"], random_state=42)\n",
    "        svm_model.fit(x_train, y_train)\n",
    "\n",
    "        # then a model trained using these parameters is tested on the internal test set\n",
    "        # I use the classes as predictions, because the confusion matrix is calculated like this\n",
    "        # however, I think the production model should return probabilities\n",
    "        model_predictions = svm_model.predict(internal_x_test)\n",
    "        print(\"model predicted\")\n",
    "\n",
    "        # the values of the testing on the internal test set are then used to select the best model\n",
    "        # ? which <average> to select?? \n",
    "        # selected micro, idk why\n",
    "        precision, recall, fbeta, support = precision_recall_fscore_support(internal_y_test, model_predictions, average='micro')\n",
    "        log_file.write(f\"{precision},{recall},{fbeta},\")\n",
    "        \n",
    "        print(\"int stats calculated\")\n",
    "\n",
    "        # then the model is tested on an external test set to assess its \"real\" performance\n",
    "        model_predictions_for_external = svm_model.predict(external_x_test)\n",
    "        ext_precision, ext_recall, ext_fbeta, ext_support = precision_recall_fscore_support(external_y_test, model_predictions_for_external, average='micro')\n",
    "        print(\"ext stats calculated\")\n",
    "        log_file.write(f\"{ext_precision},{ext_recall},{ext_fbeta}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_svm_model = SVC(C=10, kernel=\"rbf\", gamma=\"scale\", shrinking=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_svm_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "logit_roc_auc = roc_auc_score(internal_y_test, best_svm_model.predict(internal_x_test))\n",
    "# fpr, tpr, thresholds = roc_curve(internal_y_test, best_svm_model.predict_proba(internal_x_test)[:,1])\n",
    "# plt.figure()\n",
    "# plt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % logit_roc_auc)\n",
    "# plt.plot([0, 1], [0, 1],'r--')\n",
    "# plt.xlim([0.0, 1.0])\n",
    "# plt.ylim([0.0, 1.05])\n",
    "# plt.xlabel('False Positive Rate')\n",
    "# plt.ylabel('True Positive Rate')\n",
    "# plt.title('Receiver operating characteristic')\n",
    "# plt.legend(loc=\"lower right\")\n",
    "# plt.savefig('svm_ROC.png', dpi=600)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5151515151515151"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./2drdkit_autoencoder_366_svm.pickle\", \"wb\") as file:\n",
    "    pickle.dump(best_svm_model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
